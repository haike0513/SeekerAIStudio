import { translator, flatten } from "@solid-primitives/i18n";
import { makePersisted } from "@solid-primitives/storage";
import { createSignal, createMemo } from "solid-js";

export type Language = "zh-CN" | "en-US" | "ja-JP";

const dict = {
  "zh-CN": {
    app: {
      title: "AI 推理工具",
      sidebar: {
        inference: "推理",
        settings: "设置",
        models: "模型管理",
        history: "历史记录",
        workflow: "工作流",
        collapse: "收起",
      },
      theme: {
        light: "浅色",
        dark: "深色",
        auto: "自动",
      },
      language: {
        "zh-CN": "简体中文",
        "en-US": "English",
        "ja-JP": "日本語",
      },
    },
    inference: {
      title: "AI 推理界面",
      modelType: "模型类型",
      modelInit: "模型初始化",
      inference: "推理",
      ggufModel: "GGUF 模型",
      safetensorsModel: "Safetensors 模型 (Qwen3-VL)",
      loadFromFile: "从本地文件加载",
      loadFromHub: "从 HuggingFace Hub 下载",
      modelPath: "模型路径",
      tokenizerPath: "Tokenizer 路径",
      tokenizerPathOptional: "Tokenizer 路径 (可选)",
      hfRepo: "HuggingFace 仓库",
      modelFilename: "模型文件名",
      imagePath: "图像路径",
      prompt: "提示词",
      maxTokens: "最大 token 数",
      generate: "生成",
      generating: "生成中...",
      initModel: "初始化模型",
      loading: "加载中...",
      checkStatus: "检查状态",
      textInference: "文本推理",
      multimodalInference: "多模态推理（图像 + 文本）",
      result: "生成结果",
      select: "选择",
      modelLoaded: "模型已加载",
      ggufModelLoaded: "GGUF 模型已加载",
      pleaseLoadModel: "请先加载模型",
      pleaseLoadGGUFModel: "请先加载 GGUF 模型",
      pleaseEnterPrompt: "请输入提示词",
      pleaseSelectImage: "请选择图像文件",
      pleaseProvidePaths: "请提供模型路径和 tokenizer 路径",
      pleaseProvideGGUFPath: "请提供 GGUF 模型路径",
      pleaseProvideHFInfo: "请提供 HuggingFace 仓库和文件名",
      ggufNotSupportMultimodal: "GGUF 模型暂不支持多模态推理",
      error: "错误",
      placeholder: {
        modelPath: "模型文件路径 (如: model.safetensors 或模型目录)",
        ggufModelPath: "GGUF 模型文件路径 (如: model.gguf)",
        tokenizerPath: "Tokenizer 文件路径 (如: tokenizer.json 或目录)",
        tokenizerPathOptional: "Tokenizer 文件路径 (可选)",
        hfRepo: "HuggingFace 仓库 (如: HuggingFaceTB/SmolLM2-360M-Instruct-GGUF)",
        hfFilename: "模型文件名 (如: smollm2-360m-instruct-q8_0.gguf)",
        imagePath: "图像文件路径",
        prompt: "输入你的提示词...",
      },
    },
    workflow: {
      title: "工作流管理",
      description: "创建和管理 AI 推理工作流",
      create: "创建工作流",
      workflowList: "工作流列表",
      newWorkflow: "新建工作流",
      name: "名称",
      descriptionLabel: "描述",
      save: "保存",
      cancel: "取消",
      noWorkflows: "暂无工作流，点击上方按钮创建一个",
      noDescription: "无描述",
      steps: "步骤",
      run: "运行",
      delete: "删除",
      edit: "编辑",
      selectWorkflow: "请从左侧选择一个工作流",
      noSteps: "此工作流暂无步骤",
      addStep: "添加步骤",
      stepTypes: {
        inference: "推理",
        transform: "转换",
        output: "输出",
      },
      placeholder: {
        name: "输入工作流名称",
        description: "输入工作流描述（可选）",
      },
    },
  },
  "en-US": {
    app: {
      title: "AI Inference Tools",
      sidebar: {
        inference: "Inference",
        settings: "Settings",
        models: "Model Management",
        history: "History",
        workflow: "Workflow",
        collapse: "Collapse",
      },
      theme: {
        light: "Light",
        dark: "Dark",
        auto: "Auto",
      },
      language: {
        "zh-CN": "简体中文",
        "en-US": "English",
        "ja-JP": "日本語",
      },
    },
    inference: {
      title: "AI Inference Interface",
      modelType: "Model Type",
      modelInit: "Model Initialization",
      inference: "Inference",
      ggufModel: "GGUF Model",
      safetensorsModel: "Safetensors Model (Qwen3-VL)",
      loadFromFile: "Load from Local File",
      loadFromHub: "Download from HuggingFace Hub",
      modelPath: "Model Path",
      tokenizerPath: "Tokenizer Path",
      tokenizerPathOptional: "Tokenizer Path (Optional)",
      hfRepo: "HuggingFace Repository",
      modelFilename: "Model Filename",
      imagePath: "Image Path",
      prompt: "Prompt",
      maxTokens: "Max Tokens",
      generate: "Generate",
      generating: "Generating...",
      initModel: "Initialize Model",
      loading: "Loading...",
      checkStatus: "Check Status",
      textInference: "Text Inference",
      multimodalInference: "Multimodal Inference (Image + Text)",
      result: "Generated Result",
      select: "Select",
      modelLoaded: "Model Loaded",
      ggufModelLoaded: "GGUF Model Loaded",
      pleaseLoadModel: "Please load model first",
      pleaseLoadGGUFModel: "Please load GGUF model first",
      pleaseEnterPrompt: "Please enter prompt",
      pleaseSelectImage: "Please select image file",
      pleaseProvidePaths: "Please provide model path and tokenizer path",
      pleaseProvideGGUFPath: "Please provide GGUF model path",
      pleaseProvideHFInfo: "Please provide HuggingFace repository and filename",
      ggufNotSupportMultimodal: "GGUF model does not support multimodal inference yet",
      error: "Error",
      placeholder: {
        modelPath: "Model file path (e.g., model.safetensors or model directory)",
        ggufModelPath: "GGUF model file path (e.g., model.gguf)",
        tokenizerPath: "Tokenizer file path (e.g., tokenizer.json or directory)",
        tokenizerPathOptional: "Tokenizer file path (optional)",
        hfRepo: "HuggingFace repository (e.g., HuggingFaceTB/SmolLM2-360M-Instruct-GGUF)",
        hfFilename: "Model filename (e.g., smollm2-360m-instruct-q8_0.gguf)",
        imagePath: "Image file path",
        prompt: "Enter your prompt...",
      },
    },
    workflow: {
      title: "Workflow Management",
      description: "Create and manage AI inference workflows",
      create: "Create Workflow",
      workflowList: "Workflow List",
      newWorkflow: "New Workflow",
      name: "Name",
      descriptionLabel: "Description",
      save: "Save",
      cancel: "Cancel",
      noWorkflows: "No workflows yet, click the button above to create one",
      noDescription: "No description",
      steps: "steps",
      run: "Run",
      delete: "Delete",
      edit: "Edit",
      selectWorkflow: "Please select a workflow from the left",
      noSteps: "This workflow has no steps yet",
      addStep: "Add Step",
      stepTypes: {
        inference: "Inference",
        transform: "Transform",
        output: "Output",
      },
      placeholder: {
        name: "Enter workflow name",
        description: "Enter workflow description (optional)",
      },
    },
  },
  "ja-JP": {
    app: {
      title: "AI 推論ツール",
      sidebar: {
        inference: "推論",
        settings: "設定",
        models: "モデル管理",
        history: "履歴",
        workflow: "ワークフロー",
        collapse: "折りたたむ",
      },
      theme: {
        light: "ライト",
        dark: "ダーク",
        auto: "自動",
      },
      language: {
        "zh-CN": "简体中文",
        "en-US": "English",
        "ja-JP": "日本語",
      },
    },
    inference: {
      title: "AI 推論インターフェース",
      modelType: "モデルタイプ",
      modelInit: "モデル初期化",
      inference: "推論",
      ggufModel: "GGUF モデル",
      safetensorsModel: "Safetensors モデル (Qwen3-VL)",
      loadFromFile: "ローカルファイルから読み込む",
      loadFromHub: "HuggingFace Hub からダウンロード",
      modelPath: "モデルパス",
      tokenizerPath: "Tokenizer パス",
      tokenizerPathOptional: "Tokenizer パス (オプション)",
      hfRepo: "HuggingFace リポジトリ",
      modelFilename: "モデルファイル名",
      imagePath: "画像パス",
      prompt: "プロンプト",
      maxTokens: "最大トークン数",
      generate: "生成",
      generating: "生成中...",
      initModel: "モデル初期化",
      loading: "読み込み中...",
      checkStatus: "ステータス確認",
      textInference: "テキスト推論",
      multimodalInference: "マルチモーダル推論（画像 + テキスト）",
      result: "生成結果",
      select: "選択",
      modelLoaded: "モデルが読み込まれました",
      ggufModelLoaded: "GGUF モデルが読み込まれました",
      pleaseLoadModel: "まずモデルを読み込んでください",
      pleaseLoadGGUFModel: "まず GGUF モデルを読み込んでください",
      pleaseEnterPrompt: "プロンプトを入力してください",
      pleaseSelectImage: "画像ファイルを選択してください",
      pleaseProvidePaths: "モデルパスと Tokenizer パスを提供してください",
      pleaseProvideGGUFPath: "GGUF モデルパスを提供してください",
      pleaseProvideHFInfo: "HuggingFace リポジトリとファイル名を提供してください",
      ggufNotSupportMultimodal: "GGUF モデルはまだマルチモーダル推論をサポートしていません",
      error: "エラー",
      placeholder: {
        modelPath: "モデルファイルパス (例: model.safetensors またはモデルディレクトリ)",
        ggufModelPath: "GGUF モデルファイルパス (例: model.gguf)",
        tokenizerPath: "Tokenizer ファイルパス (例: tokenizer.json またはディレクトリ)",
        tokenizerPathOptional: "Tokenizer ファイルパス (オプション)",
        hfRepo: "HuggingFace リポジトリ (例: HuggingFaceTB/SmolLM2-360M-Instruct-GGUF)",
        hfFilename: "モデルファイル名 (例: smollm2-360m-instruct-q8_0.gguf)",
        imagePath: "画像ファイルパス",
        prompt: "プロンプトを入力...",
      },
    },
    workflow: {
      title: "ワークフロー管理",
      description: "AI 推論ワークフローの作成と管理",
      create: "ワークフローを作成",
      workflowList: "ワークフロー一覧",
      newWorkflow: "新しいワークフロー",
      name: "名前",
      descriptionLabel: "説明",
      save: "保存",
      cancel: "キャンセル",
      noWorkflows: "ワークフローがありません。上記のボタンをクリックして作成してください",
      noDescription: "説明なし",
      steps: "ステップ",
      run: "実行",
      delete: "削除",
      edit: "編集",
      selectWorkflow: "左側からワークフローを選択してください",
      noSteps: "このワークフローにはまだステップがありません",
      addStep: "ステップを追加",
      stepTypes: {
        inference: "推論",
        transform: "変換",
        output: "出力",
      },
      placeholder: {
        name: "ワークフロー名を入力",
        description: "ワークフローの説明を入力（オプション）",
      },
    },
  },
};

const defaultLang: Language = "zh-CN";

export function useI18n() {
  const [currentLang, setCurrentLang] = makePersisted(
    createSignal<Language>(defaultLang),
    { name: "language" }
  );
  
  // 创建当前语言的字典 memo
  const currentDict = createMemo(() => dict[currentLang()]);
  
  // 创建翻译函数
  const t = translator(() => flatten(currentDict()));
  
  const updateLanguage = (newLang: Language) => {
    setCurrentLang(newLang);
  };

  return {
    t,
    locale: currentLang,
    setLocale: updateLanguage,
  };
}
